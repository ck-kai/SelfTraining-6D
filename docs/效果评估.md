## 跑通代码
### 问题记录
1. 调用GPU相关API导致程序卡死, `x = torch.tensor([1., 2.], device=cuda)` 
驱动: 470.86
基础镜像:10.2-cudnn8-devel-ubuntu18.04

ref: https://blog.csdn.net/qq_33727302/article/details/114839729

CUDA兼容性:
    1. https://docs.nvidia.com/deploy/cuda-compatibility/index.html
    2. https://medium.com/@dun.chwong/the-simple-guide-deep-learning-with-rtx-3090-cuda-cudnn-tensorflow-keras-pytorch-e88a2a8249bc

1. 服务器驱动版本为470.86, 应使用CUDA11.4, 基础镜像改为11.4.2-cudnn8-devel-ubuntu18.04

2. 1之后构建成功,运行依然卡死, 升级pytorch版本,从1.2.0升级到1.10.0再次构建

3. 2后 torchvision报错,`AttributeError: module 'torchvision' has no attribute '__version__'`, 尝试升级torchvision到0.8.0

4. 3之后报错, `The detected CUDA version (11.4) mismatches the version that was used to compile
PyTorch (10.2). Please make sure to use the same CUDA versions.`CUDA和pytorch版本对不上,尝试降级CUDA到11.3, 按照[官网指导](https://pytorch.org/get-started/locally/)安装

5. 4之后`arch_list[-1] += '+PTX' IndexError: list index out of range`, 据查询
https://github.com/pytorch/extension-cpp/issues/71, 应该
```
python TORCH_CUDA_ARCH_LIST="YOUR_GPUs_CC+PTX" setup.py install
```
YOUR_GPUs_CC是显卡的计算能力,`nvidia-smi -L`看到显卡是两张3090, [官网](https://developer.nvidia.com/cuda-gpus#collapseOne)查询得到3090的计算能力为8.6

6. 5 构建成功,但是报错 `metaclass conflict`, 应该是pytorch版本和kaolin版本对不上, 尝试降级pytorch到1.2.0
7. 6依然卡死,升级pytorch到1.10.0
8. 7 构建成功,依然报错 `metaclass conflict`, 尝试修改源码,成功
9. docker run --rm -it -p9200:22 -v/home/pc/project/dexin:/work --runtime=nvidia --name sim2real  algenv:sim2real /bin/bash
10. KNearestNeighbor的forward不是静态函数, 解决方法: 改为静态函数,并且sim2real源码所有使用到的地方. 报错`knn_pytorch.knn(ref, query, inds) RuntimeError: Not compiled with GPU support`, 原因是docker build没有使用cuda环境, 解决方法是[安装[ nvidia-container-runtime](https://stackoverflow.com/questions/59691207/docker-build-with-nvidia-runtime)
11. knn模块编译失败, 原因是knn模块c++使用了一个被废弃的torch函数,按照[stackoverflow上的解决方法](https://stackoverflow.com/questions/55919123/cuda-for-pytorch-cuda-c-stream-and-state),修改c++代码重新编译成功





